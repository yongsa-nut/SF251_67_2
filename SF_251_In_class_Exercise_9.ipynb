{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMj0wsm01w9aKSdbXvzXMyw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yongsa-nut/SF251_67_2/blob/main/SF_251_In_class_Exercise_9.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# In-Class Exercise 9\n",
        "\n",
        "Once done, upload to MS Teams"
      ],
      "metadata": {
        "id": "dfH6h9_edDGu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pokemon Dataset Part 9\n",
        "\n",
        "In this exercise, we will predict binary outcomes using logistic regression."
      ],
      "metadata": {
        "id": "2VEkmiUvdTKw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p17eSQqWc9Xu"
      },
      "outputs": [],
      "source": [
        "!wget https://raw.githubusercontent.com/yongsa-nut/SF251_67_2/refs/heads/main/data/pokemon.csv"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import mean_squared_error, confusion_matrix, accuracy_score, classification_report\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler"
      ],
      "metadata": {
        "id": "uxRmnucwdiVg"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Load the data\n",
        "pokemon = pd.read_csv(\"pokemon.csv\")\n",
        "pokemon.columns"
      ],
      "metadata": {
        "id": "bgA4NgiOdkML"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Logistic Regression"
      ],
      "metadata": {
        "id": "hJ2GDthReEFZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will start out by just simply apply logistic regression to predict a binary outcome.\n",
        "\n",
        "**Objective**: Predict pokemon's rarity (normal vs. non normal (legendary, sublegendary, mythical)\n",
        "\n",
        "**Features**:\n",
        "- `gen`\n",
        "- `total_stats` - a sum of all stats (`hp`, `attack`, `defense`, `sp_attack`, `sp_defense`, `speed`. This is a form of feature enginerring\n",
        "- `primary_type` - We will need to convert this to one-hot encoding (or dummy variables, see lecture 10) using `pd.get_dummies(df, columns=[col names])` ([documentation](https://pandas.pydata.org/docs/reference/api/pandas.get_dummies.html)) or `sklearn.OneHotEncoder` ([documenation](https://scikit-learn.org/1.5/modules/generated/sklearn.preprocessing.OneHotEncoder.html)).\n",
        "\n",
        "**Model** ([documentation](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html)):\n",
        "- `LogisticRegression(penalty='l2', C=1.0)` (Default)\n",
        "- `LogisticRegression(penalty='l2', C=0.1)` (Stronger regularization)\n",
        "- `LogisticRegression(penalty='l1', C=1.0)`\n",
        "- `LogisticRegression(penalty='l1', C=0.1)`\n",
        "\n",
        "**Step**:\n",
        "1. Create a new column `rarity`: 0 if normal, 1 is legendary/sublegendary/mythical\n",
        "2. Create a new column `total_stats`\n",
        "3. convert 'gen' to number\n",
        "4. Create new columns for one-hot encoding of `primary_type`\n",
        "5. Create `X`, `y` dataframe\n",
        "6. Create training and testing data using `train_test_split`. 80% training and 20% testing, random_state = 100\n",
        "7. Declare the models\n",
        "8. Use cross validation to find the best model. Do 5 folds.\n",
        "9. Standardize your data first\n",
        "10. Train the best model on the whole training set\n",
        "11. Test the final model on the test set. Report accuracy and confusion matrix."
      ],
      "metadata": {
        "id": "9N4DPYnqeJBA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1) Create a new column rarity\n",
        "pokemon['rarity'] = ...\n",
        "\n",
        "# 2) Create a new column total_stats\n",
        "pokemon['total_stats'] = ...\n",
        "\n",
        "# 3) Convert gen to number\n",
        "mappings = {'I':1,'II':2,'III':3,'IV':4,'V':5,'VI':6,'VII':7,'VIII':8}\n",
        "pokemon['gen'] = ...\n",
        "\n",
        "# 4) Create new columns for one-hot encoding of primary_type\n",
        "pokemon = ...\n",
        "\n",
        "# 5) Create X and y dataframe\n",
        "X = pokemon[['gen', 'total_stats'] + list(pokemon.columns[pokemon.columns.str.startswith('primary_type_')])]\n",
        "y = ...\n",
        "\n",
        "# 6) Create training and testing data using train_test_split. 80% training and 20% testing, random_state = 100\n",
        "X_train, X_test, y_train, y_test = train_test_split(...)\n",
        "\n",
        "X_train # Check your results"
      ],
      "metadata": {
        "id": "_-QuYFoYfRLd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 7) Declare the models\n",
        "\n",
        "models = {\n",
        "    'Logistic L2 C=1': LogisticRegression(penalty='l2',C=1.0),\n",
        "    'Logistic L2 C=0.1': LogisticRegression(penalty='l2',C=0.1),\n",
        "    'Logistic L1 C=1': LogisticRegression(penalty='l1',C=1.0, solver='liblinear'),  # Need to use a different solver for l1\n",
        "    'Logistic L1 C=0.1': LogisticRegression(penalty='l1',C=0.1, solver='liblinear')\n",
        "}\n",
        "\n",
        "# 8) Use cross validation to find the best model. Do 5 folds\n",
        "cv_results = []\n",
        "\n",
        "for model_name, model in models.items():\n",
        "  # standardize the data. This is crucial for l1 to work properly.\n",
        "  # It's important that you do standardize for each fold.\n",
        "  # Pipeline is a tool to chain multiple steps of a workflow.\n",
        "  pipeline = Pipeline([\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('classifier', model)   # The last one has to be an estimator/model\n",
        "  ])\n",
        "  cv_scores = cross_val_score(estimator = pipeline,\n",
        "                                X = ...,        # Fill in your answer here\n",
        "                                y = ...,        # Fill in your answer here\n",
        "                                cv = ...,             # Fill in your answer here\n",
        "                                scoring='accuracy') # you can use precision, recall, or f1 instead too.\n",
        "  cv_results.append({\n",
        "         'Model': model_name,\n",
        "         'Accuracy': cv_scores.mean(),\n",
        "  })\n",
        "\n",
        "cv_results_df = pd.DataFrame(cv_results)\n",
        "print(cv_results_df)"
      ],
      "metadata": {
        "id": "IcsCdWn5nJeb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 9) Standardize your data first (Use these two data for train and test)\n",
        "# Note: try it without standardization. What do you see?\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# 10) Train the best model on the whole training set\n",
        "best_model = ...\n",
        "best_model.fit(...)\n",
        "\n",
        "# 11) Test the final model on the test set. Report accuracy and confusion matrix.\n",
        "y_pred = ...\n",
        "\n",
        "print(f'Accuracy: {accuracy_score(y_test, y_pred)}')\n",
        "print(classification_report(y_test, y_pred))\n",
        "print(confusion_matrix(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sP9zw9F9ocqr",
        "outputId": "f1aa25d8-6212-4f9b-9f8d-c7d6bb15270a"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.95\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.97      0.97       158\n",
            "           1       0.81      0.77      0.79        22\n",
            "\n",
            "    accuracy                           0.95       180\n",
            "   macro avg       0.89      0.87      0.88       180\n",
            "weighted avg       0.95      0.95      0.95       180\n",
            "\n",
            "[[154   4]\n",
            " [  5  17]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q** What is true positive? What is false positive? (Row is true label, Column is predicted label. See [documentation](https://scikit-learn.org/1.5/modules/generated/sklearn.metrics.confusion_matrix.html))"
      ],
      "metadata": {
        "id": "4WgOxXnQw6wu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer**:"
      ],
      "metadata": {
        "id": "Hd0x7B7PxOf5"
      }
    }
  ]
}